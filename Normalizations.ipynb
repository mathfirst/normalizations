{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f6448e",
   "metadata": {},
   "source": [
    "# The normalization methods available in Deep learning (Pytorch)\n",
    "In this notebook, we write code to verify Pytorch APIs for normalization methods.\n",
    "\n",
    "## 1. Batch normalization (per channel over one mini-batch)\n",
    "Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .\n",
    "$$\n",
    "y = \\frac{x-\\mathrm{E}(x)}{\\sqrt{\\mathrm{Var}(x)+\\epsilon}}\\cdot \\gamma + \\beta \n",
    "$$\n",
    "The mean and standard-deviation are calculated **per-dimension over the mini-batches** and $\\gamma$ and $\\beta$ are learnable parameter vectors of size $C$ (where $C$ is the channel dimension). \n",
    "\n",
    "The Pytorch API for BN is\n",
    "\n",
    "`torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)`\n",
    "\n",
    "### Statistics \n",
    "NLP: $N\\times L\\times C\\rightarrow C$\n",
    "\n",
    "CV: $N\\times C\\times H\\times W \\rightarrow C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "580dd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# We write code to verify Pytorch normalization APIs.\n",
    "# generate data\n",
    "num_channels = 3\n",
    "data = torch.randn(2,num_channels,4,4) # N * C * H * W\n",
    "# With Learnable Parameters\n",
    "torch_BN = nn.BatchNorm2d(num_channels)\n",
    "# Without Learnable Parameters\n",
    "torch_BN = nn.BatchNorm2d(num_channels, affine=False)\n",
    "\n",
    "# using Pytorch BN method\n",
    "output_torch_BN = torch_BN(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcda4080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement BN based on the formula in original BN paper \n",
    "channel_mean = torch.mean(data, keepdim=True, dim=(0,2,3)) # size: number of channels\n",
    "channel_var = torch.var(data, dim=(0,2,3), unbiased=False, keepdim=True) # size: number of channels\n",
    "our_BN = (data - channel_mean)/torch.sqrt(channel_var+1e-5)\n",
    "\n",
    "torch.allclose(our_BN, output_torch_BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f186ec",
   "metadata": {},
   "source": [
    "## 2. Layer normalization (per sample, per layer)\n",
    "### Statistics \n",
    "NLP: $N\\times L\\times C\\rightarrow N\\times L$\n",
    "\n",
    "CV: $N\\times C\\times H\\times W \\rightarrow N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5580a32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "time_steps = 3\n",
    "embedding_dim = 4\n",
    "input_data = torch.randn(batch_size, time_steps, embedding_dim) # N*L*C\n",
    "# call pytorhc api torch.LayerNorm\n",
    "pytorch_api_layerNorm = nn.LayerNorm(embedding_dim, elementwise_affine=False)\n",
    "pytorch_api_layerNorm_output = pytorch_api_layerNorm(input_data)\n",
    "# print(pytorch_api_layerNorm_output)\n",
    "# write code based on the formula\n",
    "input_mean = torch.mean(input_data, dim=-1, keepdim=True)\n",
    "input_var = torch.var(input_data, dim=-1, keepdim=True, unbiased=False)\n",
    "layerNorm_output = (input_data-input_mean)/torch.sqrt(input_var+1e-5)\n",
    "print(input_mean.shape)\n",
    "torch.allclose(layerNorm_output, pytorch_api_layerNorm_output) # verify if the results from two methods are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0321f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5, 10, 10])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Example\n",
    "N, C, H, W = 20, 5, 10, 10\n",
    "input = torch.randn(N, C, H, W)\n",
    "# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
    "# as shown in the image below\n",
    "layer_norm = nn.LayerNorm([C, H, W])\n",
    "output = layer_norm(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f11e47",
   "metadata": {},
   "source": [
    "## 3. Instance normalization (per sample, per channel)\n",
    "### Statistics \n",
    "NLP: $N\\times L\\times C\\rightarrow N\\times C$\n",
    "\n",
    "CV: $N\\times C\\times H\\times W \\rightarrow N\\times C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca30fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# call pytorch api\n",
    "pytorch_instance_normalization = nn.InstanceNorm1d(embedding_dim) # Input: (N, C, L) or (C, L), output: N*C*L or C*L\n",
    "pytorch_instance_normalization_output = pytorch_instance_normalization(input_data.transpose(-1,-2)).transpose(-1,-2)\n",
    "\n",
    "# implement the formula\n",
    "input_mean = torch.mean(input_data, dim=1, keepdim=True)\n",
    "input_var = torch.var(input_data, dim=1, keepdim=True, unbiased=False)\n",
    "instance_normalization_math = (input_data-input_mean)/torch.sqrt(input_var+1e-5)\n",
    "print(input_mean.shape) # statistics\n",
    "print(torch.allclose(pytorch_instance_normalization_output, instance_normalization_math))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572902e",
   "metadata": {},
   "source": [
    "## 4. Group normalization (per sample, per group)\n",
    "NLP: $N\\times G L\\times C//G\\rightarrow N\\times G$\n",
    "\n",
    "CV: $N\\times G\\times G//C\\times H\\times W \\rightarrow N\\times G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "319a1e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_groups = 2\n",
    "# call pytorch api\n",
    "pytorch_group_norm = nn.GroupNorm(num_groups, embedding_dim, affine=False) # input: num_groups, num_channels\n",
    "pytorch_group_norm_output = pytorch_group_norm(input_data.transpose(-1,-2)).transpose(-1,-2)\n",
    "# print(pytorch_group_norm_output)\n",
    "\n",
    "# implement the formula\n",
    "grouped_input = torch.split(input_data, num_groups, dim=-1)\n",
    "output_list = []\n",
    "for group in grouped_input:\n",
    "    input_mean = torch.mean(group, dim=(1,2), keepdim=True)\n",
    "    input_var = torch.var(group, dim=(1,2), keepdim=True, unbiased=False)\n",
    "    group_norm_output = (group-input_mean)/torch.sqrt(input_var+1e-5)\n",
    "    output_list.append(group_norm_output)\n",
    "    \n",
    "group_norm_output = torch.cat(output_list, dim=-1)\n",
    "# print(group_norm_output)\n",
    "\n",
    "torch.allclose(pytorch_group_norm_output, group_norm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa271da",
   "metadata": {},
   "source": [
    "## 5. Weight normalization (decompose weight into magnitude and direction)\n",
    "Reference: https://pytorch.org/docs/stable/generated/torch.nn.utils.weight_norm.html\n",
    "\n",
    "```torch.nn.utils.weight_norm(module, name='weight', dim=0)``` is a function instead of a class.\n",
    "Its formula is\n",
    "$$\n",
    "\\mathbf{w} = g\\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|}\n",
    "$$\n",
    "Weight normalization is a reparameterization that decouples the magnitude of a weight tensor from its direction. This replaces the parameter specified by name (e.g. `weight`) with two parameters: one specifying the magnitude (e.g. `weight_g`) and one specifying the direction (e.g. `weight_v`). \n",
    "\n",
    "By default, with `dim=0`, the norm is computed independently per output channel/plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "182d9172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a module and apply weight normalization to it\n",
    "linear = nn.Linear(embedding_dim, 3, bias=False)\n",
    "pytorch_wn_linear = nn.utils.weight_norm(linear) # the output is still a module\n",
    "pytorch_wn_linear_output = pytorch_wn_linear(input_data)\n",
    "# print(pytorch_wn_linear_output)\n",
    "\n",
    "# write weight normalization according to its principle\n",
    "# print(linear.weight.data.shape)\n",
    "direction = linear.weight/torch.norm(linear.weight.data, dim=1, keepdim=True)\n",
    "magnitude = linear.weight_g # weight_g is obtained through randomization\n",
    "wn_weight = magnitude * direction\n",
    "wn_linear_output = input_data @ wn_weight.transpose(-1,-2)\n",
    "# print(wn_linear_output)\n",
    "torch.allclose(pytorch_wn_linear_output, wn_linear_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2edd684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 0.3019, -0.1327, -0.1910],\n",
      "        [-0.1707,  0.0177, -0.1221],\n",
      "        [-0.0801, -0.4307, -0.1502],\n",
      "        [ 0.0355, -0.3091, -0.3491]], grad_fn=<WeightNormInterfaceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# more code about weight normalization in greater detail\n",
    "batch_size = 2\n",
    "feat_dim = 3\n",
    "hid_dim = 4\n",
    "data = torch.randn(batch_size, feat_dim)\n",
    "linear = nn.Linear(feat_dim, hid_dim, bias=False)\n",
    "wn_linear = nn.utils.weight_norm(linear)\n",
    "print(linear.weight.shape)\n",
    "print(linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40ab8100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_magnitude torch.Size([4, 1])\n",
      "tensor([[0.3811],\n",
      "        [0.2106],\n",
      "        [0.4631],\n",
      "        [0.4676]])\n",
      "weight_direction torch.Size([4, 3])\n",
      "tensor([[ 0.7923, -0.3481, -0.5011],\n",
      "        [-0.8105,  0.0842, -0.5796],\n",
      "        [-0.1730, -0.9300, -0.3242],\n",
      "        [ 0.0760, -0.6610, -0.7465]], grad_fn=<DivBackward0>)\n",
      "norm of weight direction: tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "weight_magnitude = torch.tensor([linear.weight[i,:].norm() for i in torch.arange(linear.weight.data.shape[0])], dtype=torch.float32)\n",
    "weight_magnitude = weight_magnitude.reshape(linear.weight.shape[0], 1)\n",
    "print(\"weight_magnitude\", weight_magnitude.shape)\n",
    "print(weight_magnitude)\n",
    "weight_direction = linear.weight/weight_magnitude\n",
    "print(\"weight_direction\", weight_direction.shape)\n",
    "print(weight_direction)\n",
    "print(\"norm of weight direction:\", (weight_direction**2).sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7f33eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3019, -0.1327, -0.1910],\n",
       "        [-0.1707,  0.0177, -0.1221],\n",
       "        [-0.0801, -0.4307, -0.1502],\n",
       "        [ 0.0355, -0.3091, -0.3491]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_direction*weight_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1739bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2420,  0.0019, -0.2964, -0.3439],\n",
       "        [-0.3751,  0.3547,  0.1179,  0.1043]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "022fbba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2420,  0.0019, -0.2964, -0.3439],\n",
       "        [-0.3751,  0.3547,  0.1179,  0.1043]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn_linear(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5305a21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2420,  0.0019, -0.2964, -0.3439],\n",
       "        [-0.3751,  0.3547,  0.1179,  0.1043]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data @ (weight_direction*weight_magnitude).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fbb7b827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_g Parameter containing:\n",
      "tensor([[0.3811],\n",
      "        [0.2106],\n",
      "        [0.4631],\n",
      "        [0.4676]], requires_grad=True)\n",
      "weight_v Parameter containing:\n",
      "tensor([[ 0.3019, -0.1327, -0.1910],\n",
      "        [-0.1707,  0.0177, -0.1221],\n",
      "        [-0.0801, -0.4307, -0.1502],\n",
      "        [ 0.0355, -0.3091, -0.3491]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# parameters of wn_linear\n",
    "for n,p in wn_linear.named_parameters():\n",
    "    print(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91b2f303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3019, -0.1327, -0.1910],\n",
       "        [-0.1707,  0.0177, -0.1221],\n",
       "        [-0.0801, -0.4307, -0.1502],\n",
       "        [ 0.0355, -0.3091, -0.3491]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the weights of the linear\n",
    "weight_v_norm = torch.tensor([wn_linear.weight_v[i,:].norm() for i in torch.arange(wn_linear.weight_v.shape[0])], dtype=torch.float32).unsqueeze(-1)\n",
    "wn_linear.weight_g * wn_linear.weight_v/weight_v_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c4c0066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3811],\n",
       "        [0.2106],\n",
       "        [0.4631],\n",
       "        [0.4676]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_v_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d12a5987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.3811],\n",
       "        [0.2106],\n",
       "        [0.4631],\n",
       "        [0.4676]], requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn_linear.weight_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eee06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
